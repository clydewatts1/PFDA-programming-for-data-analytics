{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Support Vector Regressor\n",
    "\n",
    "Imports the Support Vector Regression model from scikit-learn.\n",
    "\n",
    "SVR uses kernel methods to perform non-linear regression by mapping inputs to high-dimensional feature spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed1c0391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "# xlrd is required for reading xls Excel files\n",
    "import xlrd\n",
    "import re\n",
    "import sqlite3\n",
    "import meteostat as mt\n",
    "# Use this when displaying markdown in Jupyter Notebooks ( Gemini suggestion )\n",
    "from IPython.display import display, Markdown\n",
    "# do Support Vector Regression (SVR) to predict PV(W) from the other columns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d82e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure File Paths and Solar Parameters\n",
    "\n",
    "Sets up the directory paths for data and models used throughout the analysis:\n",
    "- Determines the notebook's current directory\n",
    "- Defines paths to training, testing, and processed data\n",
    "- Configures solar panel parameters (19 panels, 8,360W total capacity)\n",
    "- Sets location coordinates for Bettystown, Ireland\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c2ae666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current notebook directory: c:/Users/cw171001/OneDrive - Teradata/Documents/GitHub/PFDA-programming-for-data-analytics/big_project\n",
      "Data directory set to: c:/Users/cw171001/OneDrive - Teradata/Documents/GitHub/PFDA-programming-for-data-analytics/big_project/data/\n"
     ]
    }
   ],
   "source": [
    "# Determine the current path of the notebook\n",
    "notebook_path = os.path.abspath(\"big_project.ipynb\")\n",
    "notebook_dir = os.path.dirname(notebook_path).replace('\\\\', '/')\n",
    "print(\"Current notebook directory:\", notebook_dir)\n",
    "HOME_DIR = f'{notebook_dir}'\n",
    "DATA_DIR = f'{HOME_DIR}/data/'\n",
    "print(\"Data directory set to:\", DATA_DIR)\n",
    "RAW_DATA_DIR = f'{DATA_DIR}/raw_data/'\n",
    "TRAIN_DATA_DIR = f'{DATA_DIR}/training_data/'\n",
    "SQL_DB_PATH = f'{DATA_DIR}/db_sqlite/'\n",
    "SQL_DB_FILE = f'{SQL_DB_PATH}/big_project_db.sqlite3'\n",
    "BACKUP_FILE_TYPE = 'feather'  # Options: 'csv', 'feather', 'parquet'\n",
    "# Plotly setup\n",
    "plt.style.use('classic')\n",
    "sns.set_style('whitegrid')\n",
    "# Meteostat setup\n",
    "METEOSTAT_CACHE_DIR = f'{DATA_DIR}/meteostat_cache/'\n",
    "SOLAR_SITE_POSITION = (53.6985, -6.2080)  # Bettystown, Ireland\n",
    "LATITUDE, LONGITUDE = SOLAR_SITE_POSITION\n",
    "WEATHER_START_DATE = datetime.datetime(2024, 1, 1)\n",
    "WEATHER_END_DATE = datetime.datetime.now()\n",
    "# Solar panel configuration \n",
    "# Determined this using gemini and google maps measurements\n",
    "ROOF_PANE_I_ANGLE = 30  # degrees\n",
    "ROOF_PANE_II_ANGLE = 30  # degrees\n",
    "ROOF_PANE_I_AZIMUTH = 65  # degrees ( East-South-East)\n",
    "ROOF_PANE_II_AZIMUTH = 245  # degrees ( West-South-West)\n",
    "ROOF_PANE_I_COUNT = 7\n",
    "ROOF_PANE_II_COUNT = 12\n",
    "SOLAR_PANEL_POWER_RATING_W = 440  # Watts per panel\n",
    "TOTAL_SOLAR_PANE_I_CAPACITY_W = ROOF_PANE_I_COUNT * SOLAR_PANEL_POWER_RATING_W\n",
    "TOTAL_SOLAR_PANE_II_CAPACITY_W = ROOF_PANE_II_COUNT * SOLAR_PANEL_POWER_RATING_W\n",
    "TOTAL_SOLAR_CAPACITY_W = TOTAL_SOLAR_PANE_I_CAPACITY_W + TOTAL_SOLAR_PANE_II_CAPACITY_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Nighttime Threshold\n",
    "\n",
    "Filters out nighttime data where Clear Sky GHI ≤ 50 W/m². \n",
    "\n",
    "Only daytime data with meaningful solar radiation is used for training the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87aec113",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_nighlty_threshold = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864beae2",
   "metadata": {},
   "source": [
    "# Support Vector Regression (SVR) Analysis Of Solar and Weather\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data File Paths\n",
    "\n",
    "Specifies the file paths for:\n",
    "- Enriched features dataset with Copernicus weather data\n",
    "- Weather data from multiple sources\n",
    "- Training and testing datasets split by date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34515210",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_enriched_features = \"data/processed_data/hourly_solar_copernicus_enriched_data.feather\"\n",
    "file_weather_data = \"data/processed_data/hourly_weather_data.feather\"\n",
    "file_solar_data=\"data/processed_data/daily_solar_data.feather\"\n",
    "file_training_data = f\"{TRAIN_DATA_DIR}/hourly_solar_training_data.feather\"\n",
    "file_testing_data = f\"{TRAIN_DATA_DIR}/hourly_solar_testing_data.feather\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79261753",
   "metadata": {},
   "source": [
    "__Load Test and Training Data_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dc9febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daytime_train = pd.read_feather(f\"{TRAIN_DATA_DIR}/hourly_solar_training_data.feather\")\n",
    "df_daytime_test = pd.read_feather(f\"{TRAIN_DATA_DIR}/hourly_solar_testing_data.feather\")\n",
    "\n",
    "# use list comprehension to get list of columns for level 1 and level 2 from weather data\n",
    "# level 1 and levl 2 are based on condition codes from meteostat - it onehot encoding of weather conditions , with level 1 lowest level , and level 2 a summary level\n",
    "level1_features = [level for level in df_daytime_train.columns.tolist() if level.startswith('level1_')]\n",
    "level2_features = [level for level in df_daytime_train.columns.tolist() if level.startswith('level2_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Dataset Structure\n",
    "\n",
    "Shows the column names and data types of the training dataset to verify the data loaded correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0c61aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Columns",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Data Types",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "2c1ab621-b577-4b32-92bd-1c024064deed",
       "rows": [
        [
         "index",
         "index",
         "int64"
        ],
        [
         "DateTime",
         "DateTime",
         "datetime64[ns]"
        ],
        [
         "PV(W)",
         "PV(W)",
         "float64"
        ],
        [
         "Temperature(C)",
         "Temperature(C)",
         "Float64"
        ],
        [
         "Humidity(%)",
         "Humidity(%)",
         "Float64"
        ],
        [
         "Sunshine Duration",
         "Sunshine Duration",
         "Float64"
        ],
        [
         "Condition Code",
         "Condition Code",
         "Float64"
        ],
        [
         "Precipitation(mm)",
         "Precipitation(mm)",
         "Float64"
        ],
        [
         "Dew Point(C)",
         "Dew Point(C)",
         "Float64"
        ],
        [
         "Wind Direction(deg)",
         "Wind Direction(deg)",
         "Float64"
        ],
        [
         "Wind Speed(m/s)",
         "Wind Speed(m/s)",
         "Float64"
        ],
        [
         "Wind Gust(m/s)",
         "Wind Gust(m/s)",
         "Float64"
        ],
        [
         "Pressure(hPa)",
         "Pressure(hPa)",
         "Float64"
        ],
        [
         "Snow Depth(cm)",
         "Snow Depth(cm)",
         "Float64"
        ],
        [
         "level1_clear",
         "level1_clear",
         "int64"
        ],
        [
         "level1_cloudy",
         "level1_cloudy",
         "int64"
        ],
        [
         "level1_fair",
         "level1_fair",
         "int64"
        ],
        [
         "level1_fog",
         "level1_fog",
         "int64"
        ],
        [
         "level1_freezing_rain",
         "level1_freezing_rain",
         "int64"
        ],
        [
         "level1_heavy_rain",
         "level1_heavy_rain",
         "int64"
        ],
        [
         "level1_heavy_rain_shower",
         "level1_heavy_rain_shower",
         "int64"
        ],
        [
         "level1_heavy_sleet",
         "level1_heavy_sleet",
         "int64"
        ],
        [
         "level1_light_rain",
         "level1_light_rain",
         "int64"
        ],
        [
         "level1_overcast",
         "level1_overcast",
         "int64"
        ],
        [
         "level1_rain",
         "level1_rain",
         "int64"
        ],
        [
         "level1_rain_shower",
         "level1_rain_shower",
         "int64"
        ],
        [
         "level1_sleet",
         "level1_sleet",
         "int64"
        ],
        [
         "level1_sleet_shower",
         "level1_sleet_shower",
         "int64"
        ],
        [
         "level1_thunderstorm",
         "level1_thunderstorm",
         "int64"
        ],
        [
         "level2_good_visibility",
         "level2_good_visibility",
         "int64"
        ],
        [
         "level2_moderate_visibility",
         "level2_moderate_visibility",
         "int64"
        ],
        [
         "level2_poor_visibility",
         "level2_poor_visibility",
         "int64"
        ],
        [
         "level2_precipitation",
         "level2_precipitation",
         "int64"
        ],
        [
         "level2_severe_weather",
         "level2_severe_weather",
         "int64"
        ],
        [
         "# Observation period",
         "# Observation period",
         "object"
        ],
        [
         "TOA",
         "TOA",
         "float64"
        ],
        [
         "Clear sky GHI",
         "Clear sky GHI",
         "float64"
        ],
        [
         "Clear sky BHI",
         "Clear sky BHI",
         "float64"
        ],
        [
         "Clear sky DHI",
         "Clear sky DHI",
         "float64"
        ],
        [
         "Clear sky BNI",
         "Clear sky BNI",
         "float64"
        ],
        [
         "GHI",
         "GHI",
         "float64"
        ],
        [
         "BHI",
         "BHI",
         "float64"
        ],
        [
         "DHI",
         "DHI",
         "float64"
        ],
        [
         "BNI",
         "BNI",
         "float64"
        ],
        [
         "Reliability,",
         "Reliability,",
         "object"
        ],
        [
         "Time",
         "Time",
         "object"
        ],
        [
         "Date",
         "Date",
         "object"
        ],
        [
         "POA_Pane_I(W/m^2)",
         "POA_Pane_I(W/m^2)",
         "float64"
        ],
        [
         "POA_Pane_II(W/m^2)",
         "POA_Pane_II(W/m^2)",
         "float64"
        ],
        [
         "POAC_Pane_I(W/m^2)",
         "POAC_Pane_I(W/m^2)",
         "float64"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 85
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Data Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>index</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <td>DateTime</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV(W)</th>\n",
       "      <td>PV(W)</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature(C)</th>\n",
       "      <td>Temperature(C)</td>\n",
       "      <td>Float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity(%)</th>\n",
       "      <td>Humidity(%)</td>\n",
       "      <td>Float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>Hour</td>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearsky_Index</th>\n",
       "      <td>Clearsky_Index</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV(W)_error</th>\n",
       "      <td>PV(W)_error</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV(W)_error_index</th>\n",
       "      <td>PV(W)_error_index</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind Cooling</th>\n",
       "      <td>Wind Cooling</td>\n",
       "      <td>Float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Columns      Data Types\n",
       "index                          index           int64\n",
       "DateTime                    DateTime  datetime64[ns]\n",
       "PV(W)                          PV(W)         float64\n",
       "Temperature(C)        Temperature(C)         Float64\n",
       "Humidity(%)              Humidity(%)         Float64\n",
       "...                              ...             ...\n",
       "Hour                            Hour           int32\n",
       "Clearsky_Index        Clearsky_Index         float64\n",
       "PV(W)_error              PV(W)_error         float64\n",
       "PV(W)_error_index  PV(W)_error_index         float64\n",
       "Wind Cooling            Wind Cooling         Float64\n",
       "\n",
       "[85 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display column list and data types and index\n",
    "display(pd.DataFrame({\"Columns\": df_daytime_train.columns, \"Data Types\": df_daytime_train.dtypes}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c96674",
   "metadata": {},
   "source": [
    "## Histogram of various solar measures \n",
    "\n",
    "This shows a histogram of the various measures solar output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea5d208",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e5e8059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Random Forest Regressor with target: PV(W)_error and features: ['Temperature(C)', 'Humidity(%)', 'Sunshine Duration', 'Precipitation(mm)', 'Dew Point(C)', 'Wind Direction(deg)', 'Wind Speed(m/s)', 'Pressure(hPa)', 'Wind Cooling', 'Total_Power_ClearSky_Output(W)', 'Month_Sin', 'DayOfYear_Sin', 'HourOfDay_Sin', 'level2_good_visibility', 'level2_moderate_visibility', 'level2_poor_visibility', 'level2_precipitation', 'level2_severe_weather']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_cols = []\n",
    "# Columns: ['index', 'DateTime', 'PV(W)', 'Temperature(C)', 'Humidity(%)', 'Sunshine Duration', 'Condition Code', 'Precipitation(mm)', 'Dew Point(C)', 'Wind Direction(deg)', 'Wind Speed(m/s)', 'Wind Gust(m/s)', 'Pressure(hPa)', 'Snow Depth(cm)', 'level1_clear', 'level1_cloudy', 'level1_fair', 'level1_fog', 'level1_freezing_rain', 'level1_heavy_rain', 'level1_heavy_rain_shower', 'level1_heavy_sleet', 'level1_light_rain', 'level1_overcast', 'level1_rain', 'level1_rain_shower', 'level1_sleet', 'level1_sleet_shower', 'level1_thunderstorm', 'level2_good_visibility', 'level2_moderate_visibility', 'level2_poor_visibility', 'level2_precipitation', 'level2_severe_weather', '# Observation period', 'TOA', 'Clear sky GHI', 'Clear sky BHI', 'Clear sky DHI', 'Clear sky BNI', 'GHI', 'BHI', 'DHI', 'BNI', 'Reliability,', 'Time', 'Date', 'POA_Pane_I(W/m^2)', 'POA_Pane_II(W/m^2)', 'POAC_Pane_I(W/m^2)', 'POAC_Pane_II(W/m^2)', 'Power_Pane_I(W)', 'Power_Pane_II(W)', 'Power_ClearSky_Pane_I(W)', 'Power_ClearSky_Pane_II(W)', 'Total_Power_Output(W)', 'Total_Power_ClearSky_Output(W)', 'WeekOfYear', 'Month_Sin', 'DayOfYear_Sin', 'HourOfDay_Sin']\n",
    "feature_cols = []\n",
    "test_no=\"999\"\n",
    "# Define target column\n",
    "\n",
    "#target_col = 'PV(W)'\n",
    "#target_col = 'Clearsky_Index'\n",
    "target_col = 'PV(W)_error'\n",
    "#target_col = 'PV(W)_error_index'\n",
    "#\n",
    "test_name=f\"Optimal Features  No Level 2 and No Clearsky - Target {target_col}\"\n",
    "notes=\"This is the best combination of features exclude level 2 and no clearsky weather features\"\n",
    "\n",
    "# Put change here to add more features\n",
    "feature_cols.append('Temperature(C)')\n",
    "feature_cols.append('Humidity(%)')\n",
    "feature_cols.append('Sunshine Duration')\n",
    "#feature_cols.append('Condition Code')\n",
    "feature_cols.append('Precipitation(mm)')\n",
    "feature_cols.append('Dew Point(C)')\n",
    "feature_cols.append('Wind Direction(deg)')\n",
    "feature_cols.append('Wind Speed(m/s)')\n",
    "#feature_cols.append('Wind Gust(m/s)')\n",
    "feature_cols.append('Pressure(hPa)')\n",
    "#feature_cols.append('Snow Depth(cm)')\n",
    "feature_cols.append('Wind Cooling')\n",
    "#  level1_features\n",
    "#feature_cols.append('# Observation period')\n",
    "#feature_cols.append('TOA')\n",
    "#feature_cols.append('Clear sky GHI')\n",
    "#feature_cols.append('Clear sky BHI')\n",
    "#feature_cols.append('Clear sky DHI')\n",
    "#feature_cols.append('Clear sky BNI')\n",
    "# Relate to target #feature_cols.append('GHI')\n",
    "# Relate to target #feature_cols.append('BHI')\n",
    "# Relate to target #feature_cols.append('DHI')\n",
    "# Relate to target #feature_cols.append('BNI')\n",
    "# String ignore feature_cols.append('Reliability,')\n",
    "# Relate to target #feature_cols.append('POA_Pane_I(W/m^2)')\n",
    "# Relate to target #feature_cols.append('POA_Pane_II(W/m^2)')\n",
    "# Relate to target #feature_cols.append('POAC_Pane_I(W/m^2)')\n",
    "# Relate to target #feature_cols.append('POAC_Pane_II(W/m^2)')\n",
    "# Relate to target #feature_cols.append('Power_Pane_I(W)')\n",
    "# Relate to target #feature_cols.append('Power_Pane_II(W)')\n",
    "#feature_cols.append('Power_ClearSky_Pane_I(W)')\n",
    "#feature_cols.append('Power_ClearSky_Pane_II(W)')\n",
    "# Relate to target #feature_cols.append('Total_Power_Output(W)')\n",
    "feature_cols.append('Total_Power_ClearSky_Output(W)')\n",
    "#feature_cols.append('WeekOfYear')\n",
    "feature_cols.append('Month_Sin')\n",
    "feature_cols.append('DayOfYear_Sin')\n",
    "feature_cols.append('HourOfDay_Sin')\n",
    "#  level2_features\n",
    "feature_cols += level2_features\n",
    "#  level1_features\n",
    "#feature_cols += level1_features\n",
    "\n",
    "print(f\"\\nTesting Random Forest Regressor with target: {target_col} and features: {feature_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training and Testing Data\n",
    "\n",
    "Creates the feature matrices (X) and target vectors (y) for both training and testing datasets.\n",
    "\n",
    "Splits the data into independent variables (features) and dependent variable (target) for model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8477367a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Random Forest Regressor with target: PV(W)_error and features: ['Temperature(C)', 'Humidity(%)', 'Sunshine Duration', 'Precipitation(mm)', 'Dew Point(C)', 'Wind Direction(deg)', 'Wind Speed(m/s)', 'Pressure(hPa)', 'Wind Cooling', 'Total_Power_ClearSky_Output(W)', 'Month_Sin', 'DayOfYear_Sin', 'HourOfDay_Sin', 'level2_good_visibility', 'level2_moderate_visibility', 'level2_poor_visibility', 'level2_precipitation', 'level2_severe_weather']\n",
      "X_train shape: (2192, 18)\n",
      "y_train shape: (2192,)\n",
      "X_test shape: (2194, 18)\n",
      "y_test shape: (2194,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nTesting Random Forest Regressor with target: {target_col} and features: {feature_cols}\")\n",
    "# Create x and y for training and testing\n",
    "X_train = df_daytime_train[feature_cols]\n",
    "y_train = df_daytime_train[target_col]\n",
    "X_test = df_daytime_test[feature_cols]\n",
    "y_test = df_daytime_test[target_col]\n",
    "# print shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "# Save test and training x and y to feather files\n",
    "# This allows later analysis without needing to redo the train test split\n",
    "X_train.to_pickle(f\"{TRAIN_DATA_DIR}/X_train_test_no_{test_no}.pickle\")\n",
    "y_train.to_pickle(f\"{TRAIN_DATA_DIR}/y_train_test_no_{test_no}.pickle\")\n",
    "X_test.to_pickle(f\"{TRAIN_DATA_DIR}/X_test_test_no_{test_no}.pickle\")\n",
    "y_test.to_pickle(f\"{TRAIN_DATA_DIR}/y_test_test_no_{test_no}.pickle\")\n",
    "# Also put test no , name and notes in a dataframe and save as feather\n",
    "test_info_df = pd.DataFrame({\n",
    "    \"Test No\": [test_no],\n",
    "    \"Test Name\": [test_name],\n",
    "    \"Notes\": [notes],\n",
    "    'target_col': [target_col],\n",
    "    'feature_cols': [feature_cols]\n",
    "})\n",
    "test_info_df.to_feather(f\"{TRAIN_DATA_DIR}/test_info_test_no_{test_no}.pickle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "Uses the trained model to make predictions on both training and testing datasets.\n",
    "\n",
    "These predictions are used to evaluate model performance and analyze errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf1178be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fine-Tuned Search...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      3\u001b[39m param_grid_fine = {\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# If your best C was 0.1 or 0.2, we search in between\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mregressor__svr__C\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.05\u001b[39m, \u001b[32m0.1\u001b[39m, \u001b[32m0.15\u001b[39m, \u001b[32m0.2\u001b[39m, \u001b[32m0.3\u001b[39m], \n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mregressor__svr__gamma\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0.001\u001b[39m, \u001b[32m0.005\u001b[39m, \u001b[32m0.01\u001b[39m]\n\u001b[32m     12\u001b[39m }\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting Fine-Tuned Search...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m search_fine = \u001b[43mGridSearchCV\u001b[49m(\n\u001b[32m     17\u001b[39m     model, \n\u001b[32m     18\u001b[39m     param_grid_fine, \n\u001b[32m     19\u001b[39m     cv=\u001b[32m5\u001b[39m, \n\u001b[32m     20\u001b[39m     scoring=\u001b[33m'\u001b[39m\u001b[33mr2\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     21\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m search_fine.fit(X_train, y_train)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest Fine-Tuned Params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_fine.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "# Fine-tuning around the \"Robust\" values\n",
    "# We zoom in on the lower end of C and Gamma\n",
    "param_grid_fine = {\n",
    "    # If your best C was 0.1 or 0.2, we search in between\n",
    "    'regressor__svr__C': [0.05, 0.1, 0.15, 0.2, 0.3], \n",
    "    \n",
    "    # Fine-tuning how \"wide\" the error tube is\n",
    "    'regressor__svr__epsilon': [0.05, 0.1, 0.15, 0.2], \n",
    "    \n",
    "    # Fine-tuning the curve shape\n",
    "    'regressor__svr__gamma': ['auto', 0.001, 0.005, 0.01]\n",
    "}\n",
    "\n",
    "print(\"Starting Fine-Tuned Search...\")\n",
    "\n",
    "search_fine = GridSearchCV(\n",
    "    model, \n",
    "    param_grid_fine, \n",
    "    cv=5, \n",
    "    scoring='r2', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search_fine.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Fine-Tuned Params: {search_fine.best_params_}\")\n",
    "print(f\"Best Score: {search_fine.best_score_}\")\n",
    "\n",
    "final_model = search_fine.best_estimator_\n",
    "y_test_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Target Variable Transformation\n",
    "\n",
    "Checks if the target variable needs inverse transformation after scaling.\n",
    "\n",
    "For PV(W), no inverse transformation is needed as predictions are already in the original scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504920cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Depending on target column, inverse transform if necessary\n",
    "if target_col in ['PV(W)']:\n",
    "    y_train_pvw_pred = y_train_pred\n",
    "    y_train_pvw = y_train\n",
    "    y_test_pvw_pred = y_test_pred\n",
    "    y_test_pvw = y_test\n",
    "elif target_col in ['PV(W)_error']:\n",
    "    y_train_pvw_pred = y_train_pred + X_train['Total_Power_ClearSky_Output(W)']\n",
    "    y_train_pvw = y_train + X_train['Total_Power_ClearSky_Output(W)']\n",
    "    y_test_pvw_pred = y_test_pred + X_test['Total_Power_ClearSky_Output(W)']\n",
    "    y_test_pvw = y_test + X_test['Total_Power_ClearSky_Output(W)']\n",
    "\n",
    "if target_col in ['Clearsky_Index']:\n",
    "    y_train_pvw_pred = y_train_pred * X_train['Total_Power_ClearSky_Output(W)']\n",
    "    y_train_pvw = y_train * X_train['Total_Power_ClearSky_Output(W)']\n",
    "    y_test_pvw_pred = y_test_pred * X_test['Total_Power_ClearSky_Output(W)']\n",
    "    y_test_pvw = y_test * X_test['Total_Power_ClearSky_Output(W)']\n",
    "elif target_col in ['PV(W)_error_index']:\n",
    "    y_train_pvw_pred = (y_train_pred * X_train['Total_Power_ClearSky_Output(W)']) + X_train['Total_Power_ClearSky_Output(W)']\n",
    "    y_train_pvw = (y_train * X_train['Total_Power_ClearSky_Output(W)']) + X_train['Total_Power_ClearSky_Output(W)']\n",
    "    y_test_pvw_pred = (y_test_pred * X_test['Total_Power_ClearSky_Output(W)']) + X_test['Total_Power_ClearSky_Output(W)']\n",
    "    y_test_pvw = (y_test * X_test['Total_Power_ClearSky_Output(W)']) + X_test['Total_Power_ClearSky_Output(W)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de79b9cd",
   "metadata": {},
   "source": [
    "__Metrics for Tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df434e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 3 main metrics: RMSE, MAE, R2 for both training and testing# # do SVR regression to predict PV(W) from the other columnsfrom sklearn.model_selection import train_test_splitfrom sklearn.svm import SVRfrom sklearn.metrics import mean_squared_error, r2_score# do SVR regression to predict PV(W) from the other columnsfrom sklearn.model_selection import train_test_splitfrom sklearn.svm import SVRfrom sklearn.metrics import mean_squared_error, r2_scoredef calculate_metrics(y_true, y_pred):    rmse = np.sqrt(mean_squared_error(y_true, y_pred))    mae = np.mean(np.abs(y_true - y_pred))    r2 = r2_score(y_true, y_pred)    # and normalized based on MAX of y_true - the standard practice for solar prediction    normalization_factor = np.max(y_true) - np.min(y_true)    #normalization_factor = 8400 # based on max PV(W) based on system size    n_rmse = rmse / normalization_factor    n_mae = mae / normalization_factor    # calculate accuracy as 1 - (mae / mean of y_true)    accuracy_score = 1 - (mae / np.mean(y_true))    return rmse, mae, r2 , n_rmse, n_mae, accuracy_scoretrain_rmse, train_mae, train_r2, train_n_rmse, train_n_mae, train_accuracy = calculate_metrics(y_train, y_train_pred)test_rmse, test_mae, test_r2, test_n_rmse, test_n_mae, test_accuracy = calculate_metrics(y_test, y_test_pred)train_rmse_pvw, train_mae_pvw, train_r2_pvw, train_n_rmse_pvw, train_n_mae_pvw, train_accuracy_pvw = calculate_metrics(y_train_pvw, y_train_pvw_pred)test_rmse_pvw, test_mae_pvw, test_r2_pvw, test_n_rmse_pvw, test_n_mae_pvw, test_accuracy_pvw = calculate_metrics(y_test_pvw, y_test_pvw_pred)# print the metrics , output into a markdown table , include percentages for n_rmse and n_mae and accuracymk_string = \"\"\"| Metric       | Training Set        | Testing Set         ||--------------|---------------------|---------------------|| RMSE         | {:.2f}              | {:.2f}              || MAE          | {:.2f}              | {:.2f}              || R2           | {:.4f}              | {:.4f}              || N-RMSE (%)   | {:.4f}              | {:.4f}              || N-MAE (%)    | {:.4f}              | {:.4f}              || Accuracy (%) | {:.4f}              | {:.4f}              |\"\"\".format(    train_rmse, test_rmse,    train_mae, test_mae,    train_r2, test_r2,    train_n_rmse*100, test_n_rmse*100,    train_n_mae*100, test_n_mae*100,    train_accuracy*100, test_accuracy*100)from IPython.display import display, Markdowndisplay(Markdown(f\"### SVR Regressor Performance Metrics {target_col}\\n\" + mk_string))mk_string = \"\"\"| Metric       | Training Set        | Testing Set         ||--------------|---------------------|---------------------|| RMSE         | {:.2f}              | {:.2f}              || MAE          | {:.2f}              | {:.2f}              || R2           | {:.4f}              | {:.4f}              || N-RMSE (%)   | {:.4f}              | {:.4f}              || N-MAE (%)    | {:.4f}              | {:.4f}              || Accuracy (%) | {:.4f}              | {:.4f}              |\"\"\".format(    train_rmse_pvw, test_rmse_pvw,    train_mae_pvw, test_mae_pvw,    train_r2_pvw, test_r2_pvw,    train_n_rmse_pvw*100, test_n_rmse_pvw*100,    train_n_mae_pvw*100, test_n_mae_pvw*100,    train_accuracy_pvw*100, test_accuracy_pvw*100)from IPython.display import display, Markdowndisplay(Markdown(f\"### SVR Regressor Performance Metrics PV(W)\\n\" + mk_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Performance Metrics\n",
    "\n",
    "Computes evaluation metrics for both training and testing datasets:\n",
    "- **RMSE** (Root Mean Squared Error): Average prediction error magnitude\n",
    "- **MAE** (Mean Absolute Error): Average absolute prediction error\n",
    "- **R² Score**: Proportion of variance explained by the model\n",
    "\n",
    "These metrics help assess model performance and generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 3 main metrics: RMSE, MAE, R2 for both training and testing\n",
    "# # do XBOOST regression to predict PV(W) from the other columns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# do XBOOST regression to predict PV(W) from the other columns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    # and normalized based on MAX of y_true - the standard practice for solar prediction\n",
    "    normalization_factor = np.max(y_true) - np.min(y_true)\n",
    "    #normalization_factor = 8400 # based on max PV(W) based on system size\n",
    "    n_rmse = rmse / normalization_factor\n",
    "    n_mae = mae / normalization_factor\n",
    "    # calculate accuracy as 1 - (mae / mean of y_true)\n",
    "    accuracy_score = 1 - (mae / np.mean(y_true))\n",
    "    # Calculate Explained Variance\n",
    "    explained_var = explained_variance_score(y_true, y_pred)\n",
    "    return rmse, mae, r2 , n_rmse, n_mae, accuracy_score, explained_var\n",
    "train_rmse, train_mae, train_r2, train_n_rmse, train_n_mae, train_accuracy, train_explained_var = calculate_metrics(y_train, y_train_pred)\n",
    "test_rmse, test_mae, test_r2, test_n_rmse, test_n_mae, test_accuracy, test_explained_var = calculate_metrics(y_test, y_test_pred)\n",
    "train_rmse_pvw, train_mae_pvw, train_r2_pvw, train_n_rmse_pvw, train_n_mae_pvw, train_accuracy_pvw, train_explained_var_pvw = calculate_metrics(y_train_pvw, y_train_pvw_pred)\n",
    "test_rmse_pvw, test_mae_pvw, test_r2_pvw, test_n_rmse_pvw, test_n_mae_pvw, test_accuracy_pvw, test_explained_var_pvw = calculate_metrics(y_test_pvw, y_test_pvw_pred)\n",
    "# print the metrics , output into a markdown table , include percentages for n_rmse and n_mae and accuracy\n",
    "mk_string = \"\"\"| Metric       | Training Set        | Testing Set         |\n",
    "|--------------|---------------------|---------------------|\n",
    "| RMSE         | {:.2f}              | {:.2f}              |\n",
    "| MAE          | {:.2f}              | {:.2f}              |\n",
    "| R2           | {:.4f}              | {:.4f}              |\n",
    "| N-RMSE (%)   | {:.4f}              | {:.4f}              |\n",
    "| N-MAE (%)    | {:.4f}              | {:.4f}              |\n",
    "| Accuracy (%) | {:.4f}              | {:.4f}              |\n",
    "| Explained Variance | {:.4f}         | {:.4f}              |\n",
    "\"\"\".format(\n",
    "    train_rmse, test_rmse,\n",
    "    train_mae, test_mae,\n",
    "    train_r2, test_r2,\n",
    "    train_n_rmse*100, test_n_rmse*100,\n",
    "    train_n_mae*100, test_n_mae*100,\n",
    "    train_accuracy*100, test_accuracy*100,\n",
    "    train_explained_var, test_explained_var\n",
    ")\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(f\"### SPV Regressor Performance Metrics {target_col}\\n\" + mk_string))\n",
    "mk_string = \"\"\"| Metric       | Training Set        | Testing Set         |\n",
    "|--------------|---------------------|---------------------|\n",
    "| RMSE         | {:.2f}              | {:.2f}              |\n",
    "| MAE          | {:.2f}              | {:.2f}              |\n",
    "| R2           | {:.4f}              | {:.4f}              |\n",
    "| N-RMSE (%)   | {:.4f}              | {:.4f}              |\n",
    "| N-MAE (%)    | {:.4f}              | {:.4f}              |\n",
    "| Accuracy (%) | {:.4f}              | {:.4f}              |\n",
    "| Explained Variance | {:.4f}         | {:.4f}              |\n",
    "\"\"\".format(\n",
    "    train_rmse_pvw, test_rmse_pvw,\n",
    "    train_mae_pvw, test_mae_pvw,\n",
    "    train_r2_pvw, test_r2_pvw,\n",
    "    train_n_rmse_pvw*100, test_n_rmse_pvw*100,\n",
    "    train_n_mae_pvw*100, test_n_mae_pvw*100,\n",
    "    train_accuracy_pvw*100, test_accuracy_pvw*100,\n",
    "    train_explained_var_pvw, test_explained_var_pvw\n",
    ")\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(f\"### SPV Regressor Performance Metrics PV(W)\\n\" + mk_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e1681",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442628e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Pipeline with Scaling (Crucial for SVR)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('svr', SVR(kernel='rbf'))\n",
    "])\n",
    "\n",
    "model = TransformedTargetRegressor(regressor=pipeline, transformer=StandardScaler())\n",
    "\n",
    "# 2. \"Anti-Overfitting\" Parameter Grid\n",
    "# We focus on smaller C values (0.1 to 10) and smaller Gamma values.\n",
    "# This forces the model to be 'stiff' and generalize better.\n",
    "param_grid = {\n",
    "    'regressor__svr__C': [0.1, 0.5, 1, 5, 10],       # Removed 100, 1000 (Too strict)\n",
    "    'regressor__svr__gamma': ['auto', 0.01, 0.001],  # Removed 'scale' (often too wiggly)\n",
    "    'regressor__svr__epsilon': [0.1, 0.2, 0.5]       # Higher epsilon = ignore small errors\n",
    "}\n",
    "\n",
    "print(\"Searching for a smoother model...\")\n",
    "\n",
    "search = GridSearchCV(\n",
    "    model, \n",
    "    param_grid, \n",
    "    cv=5,                # Increased CV to 5 to ensure consistency\n",
    "    scoring='r2', \n",
    "    n_jobs=-1,\n",
    "    return_train_score=True # We need this to check for overfitting\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# 3. Diagnose the Overfitting\n",
    "results = search.cv_results_\n",
    "best_index = search.best_index_\n",
    "\n",
    "train_score = results['mean_train_score'][best_index]\n",
    "test_score = results['mean_test_score'][best_index]\n",
    "\n",
    "print(f\"\\nBest Parameters: {search.best_params_}\")\n",
    "print(f\"Training R2: {train_score:.4f}\")\n",
    "print(f\"Testing  R2: {test_score:.4f}\")\n",
    "print(f\"Gap: {train_score - test_score:.4f}\")\n",
    "\n",
    "if (train_score - test_score) > 0.10:\n",
    "    print(\"WARNING: Still overfitting significantly. Try reducing C further.\")\n",
    "else:\n",
    "    print(\"Success: The gap between Train and Test is acceptable.\")\n",
    "\n",
    "# 4. Final Prediction\n",
    "best_model = search.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Performance\n",
    "\n",
    "Creates plots to visualize model predictions against actual values:\n",
    "- Scatter plots comparing predicted vs actual values\n",
    "- Separate plots for training and testing data\n",
    "- Helps assess model fit and identify potential issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot risduals per hour of day\n",
    "fig, ax = plt.subplots(2,1,figsize=(10,12))\n",
    "ax = ax.flatten()\n",
    "sns.scatterplot(x=df_daytime_test['DateTime'].dt.hour, y=y_test - y_test_pred, color='blue', label='Test Data', alpha=0.5,ax=ax[0])\n",
    "sns.scatterplot(x=df_daytime_train['DateTime'].dt.hour, y=y_train - y_train_pred\n",
    ", color='green', label='Train Data', alpha=0.4, ax=ax[0])\n",
    "ax[0].axhline(y=0, color='red', linestyle='--')\n",
    "ax[0].set_title('Residuals vs Hour of Day')\n",
    "ax[0].set_xlabel('Hour of Day')\n",
    "ax[0].set_ylabel('Residuals (Actual - Predicted)')\n",
    "ax[0].legend()\n",
    "sns.scatterplot(x=df_daytime_test['DateTime'].dt.hour, y=y_test_pvw - y_test_pvw_pred, color='blue', label='Test Data', alpha=0.5,ax=ax[1])\n",
    "sns.scatterplot(x=df_daytime_train['DateTime'].dt.hour, y=y_train_pvw - y_train_pvw_pred\n",
    ", color='green', label='Train Data', alpha=0.4, ax=ax[1])\n",
    "ax[1].axhline(y=0, color='red', linestyle='--')\n",
    "ax[1].set_title('Residuals vs Hour of Day')\n",
    "ax[1].set_xlabel('Hour of Day')\n",
    "ax[1].set_ylabel('Residuals (Actual - Predicted)')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Performance\n",
    "\n",
    "Creates plots to visualize model predictions against actual values:\n",
    "- Scatter plots comparing predicted vs actual values\n",
    "- Separate plots for training and testing data\n",
    "- Helps assess model fit and identify potential issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual histogram\n",
    "def plot_residuals_histogram():\n",
    "    # Keep the main fig and ax definition\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(18, 14)) # Slightly taller to prevent title overlap\n",
    "    ax = ax.flatten()\n",
    "    fig.suptitle('Residuals Analysis', fontsize=18)\n",
    "    \n",
    "    # Subplot 1: Histograms\n",
    "    sns.histplot(y_test - y_test_pred, color='blue', label='Test Data', kde=True, bins=30, ax=ax[0])\n",
    "    sns.histplot(y_train - y_train_pred, color='green', label='Train Data', kde=True, bins=30, ax=ax[0])\n",
    "    ax[0].set_title('Residuals Histogram')\n",
    "    ax[0].legend() # Added legend here so you can see which is which\n",
    "\n",
    "    # Subplot 2: Density (Removed the extra plt.figure call)\n",
    "    sns.kdeplot(y_test - y_test_pred, color='blue', label='Test Data', fill=True, ax=ax[1])\n",
    "    sns.kdeplot(y_train - y_train_pred, color='green', label='Train Data', fill=True, ax=ax[1])\n",
    "    ax[1].set_title('Residuals Density Plot')\n",
    "    ax[1].set_xlabel('Residuals (Actual - Predicted)')\n",
    "    ax[1].set_ylabel('Density')\n",
    "    ax[1].legend()\n",
    "    # plot difference of residuals between train and test as histogram\n",
    "    sns.histplot((y_test - y_test_pred) - (y_train - y_train_pred), color='red', label='Test - Train Residuals', kde=True, stat=\"count\", bins=30, ax=ax[2])\n",
    "    ax[2].set_title('Difference of Residuals Histogram')\n",
    "    ax[2].set_xlabel('Difference of Residuals')\n",
    "    ax[2].set_ylabel('Frequency')\n",
    "    ax[2].legend()\n",
    "\n",
    "    # plot difference of residuals\n",
    "    sns.kdeplot((y_test - y_test_pred) - (y_train - y_train_pred), color='red', label='Test - Train Residuals', fill=True, ax=ax[3])\n",
    "    ax[3].set_title('Difference of Residuals Density Plot')\n",
    "    ax[3].set_xlabel('Difference of Residuals')\n",
    "    ax[3].set_ylabel('Density')\n",
    "    ax[3].legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_residuals_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQ Plot of Residuals\n",
    "\n",
    "Creates a Quantile-Quantile plot to assess if residuals follow a normal distribution.\n",
    "\n",
    "Points should lie close to the diagonal line if residuals are normally distributed, indicating the residuals meet the assumption of normality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add QQ plot for residuals\n",
    "import scipy.stats as stats\n",
    "plt.figure(figsize=(10,6))\n",
    "stats.probplot(y_test - y_test_pred, dist=\"norm\", plot=plt)\n",
    "plt.title('QQ Plot of Residuals (Test Data)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc672ad0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80628f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted for first 200 samples\n",
    "fig, ax = plt.subplots(4,1,figsize=(15, 18))\n",
    "ax = ax.flatten()\n",
    "if target_col == 'PV(W)':\n",
    "    ax[0].plot(y_test[:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    ax[0].plot(y_test_pred[:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    ax[0].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Test Samples)')\n",
    "    ax[0].set_xlabel('Sample Index')\n",
    "    ax[0].set_ylabel('Power Output (W)')\n",
    "    ax[0].legend()\n",
    "    # add a gap between test and train plots\n",
    "    ax[1].plot(y_train[:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    ax[1].plot(y_train_pred[:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    ax[1].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Training Samples)')\n",
    "    ax[1].set_xlabel('Sample Index')\n",
    "    ax[1].set_ylabel('Power Output (W)')\n",
    "    ax[1].legend()\n",
    "if target_col == 'Clearsky_Index':\n",
    "    ax[0].plot(y_test[:200] *  df_daytime_test['Total_Power_ClearSky_Output(W)'][:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    ax[0].plot(y_test_pred[:200] *  df_daytime_test['Total_Power_ClearSky_Output(W)'][:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    ax[0].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Test Samples)')\n",
    "    ax[0].set_xlabel('Sample Index')\n",
    "    ax[0].set_ylabel('Power Output (W)')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(y_train[:200] *  df_daytime_train['Total_Power_ClearSky_Output(W)'][:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    ax[1].plot(y_train_pred[:200] *  df_daytime_train['Total_Power_ClearSky_Output(W)'][:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    ax[1].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Training Samples)')\n",
    "    ax[1].set_xlabel('Sample Index')\n",
    "    ax[1].set_ylabel('Power Output (W)')\n",
    "    ax[1].legend()\n",
    "\n",
    "    ax[2].plot(y_test[:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    ax[2].plot(y_test_pred[:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    ax[2].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Test Samples)')\n",
    "    ax[2].set_xlabel('Sample Index')\n",
    "    ax[2].set_ylabel(target_col)\n",
    "    ax[2].legend()\n",
    "\n",
    "    ax[3].plot(y_train[:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    ax[3].plot(y_train_pred[:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    ax[3].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Training Samples)')\n",
    "    ax[3].set_xlabel('Sample Index')\n",
    "    ax[3].set_ylabel(target_col)\n",
    "    ax[3].legend()\n",
    "if target_col == 'PV(W)_error' :\n",
    "    ax[0].plot((y_test[:200]+ df_daytime_test['Total_Power_ClearSky_Output(W)'][:200]).clip(lower=0), label=f'Actual  Calculated PV(W) Clipped' , color='blue', alpha=0.7)\n",
    "    ax[0].plot((y_test_pred[:200]+ df_daytime_test['Total_Power_ClearSky_Output(W)'][:200]).clip(lower=0), label='Predicted Calculated PV(W) Clipped', color='red', alpha=0.7)\n",
    "    ax[0].plot(df_daytime_test['PV(W)'][:200], label='Actual PV(W)', color='green', linestyle=':', alpha=0.7)\n",
    "    ax[0].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Test Samples)')\n",
    "    ax[0].set_xlabel('Sample Index')\n",
    "    ax[0].set_ylabel('Power Output (W)')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot((y_train[:200] + df_daytime_train['Total_Power_ClearSky_Output(W)'][:200]).clip(lower=0), label=f'Actual Calculated PV(W)  Clipped', color='blue', alpha=0.7)\n",
    "    ax[1].plot((y_train_pred[:200]+ df_daytime_train['Total_Power_ClearSky_Output(W)'][:200]).clip(lower=0), label='Predicted Calculated PV(W)  Clipped', color='red', linestyle='--', alpha=0.7)\n",
    "    ax[1].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Training Samples)')\n",
    "    ax[1].set_xlabel('Sample Index')\n",
    "    ax[1].set_ylabel('Power Output (W)')\n",
    "    ax[1].legend()\n",
    "    ax[2].plot(y_test_pvw[:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    ax[2].plot(y_test_pvw_pred[:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    ax[2].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Test Samples)')\n",
    "    ax[2].set_xlabel('Sample Index')\n",
    "    ax[2].set_ylabel(target_col)\n",
    "    #ax[2].legend()\n",
    "    #ax[2].plot(y_test[:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    #ax[2].plot(y_test_pred[:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    #ax[2].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Test Samples)')\n",
    "    #ax[2].set_xlabel('Sample Index')\n",
    "    #ax[2].set_ylabel(target_col)\n",
    "    #ax[2].legend()\n",
    "\n",
    "    ax[3].plot(y_train[:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    ax[3].plot(y_train_pred[:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    ax[3].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Training Samples)')\n",
    "    ax[3].set_xlabel('Sample Index')\n",
    "    ax[3].set_ylabel        \n",
    "if target_col == 'PV(W)_error_index':\n",
    "    ax[0].plot(y_test[:200] *  df_daytime_test['Total_Power_ClearSky_Output(W)'][:200] + df_daytime_test['Total_Power_ClearSky_Output(W)'][:200], label=f'Actual Calculated PV(W)', color='blue', alpha=0.7)\n",
    "    ax[0].plot(y_test_pred[:200] *  df_daytime_test['Total_Power_ClearSky_Output(W)'][:200] + df_daytime_test['Total_Power_ClearSky_Output(W)'][:200], label='Predicted Calculated PV(W)', color='red', linestyle='--', alpha=0.7)\n",
    "    ax[0].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Test Samples)')\n",
    "    ax[0].set_xlabel('Sample Index')\n",
    "    ax[0].set_ylabel('Power Output (W)')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(y_train[:200] *  df_daytime_train['Total_Power_ClearSky_Output(W)'][:200] + df_daytime_train['Total_Power_ClearSky_Output(W)'][:200], label=f'Actual Calculated PV(W)', color='blue', alpha=0.7)\n",
    "    ax[1].plot(y_train_pred[:200] *  df_daytime_train['Total_Power_ClearSky_Output(W)'][:200] + df_daytime_train['Total_Power_ClearSky_Output(W)'][:200], label='Predicted Calculated PV(W)', color='red', linestyle='--', alpha=0.7)\n",
    "    ax[1].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Training Samples)')\n",
    "    ax[1].set_xlabel('Sample Index')\n",
    "    ax[1].set_ylabel('Power Output (W)')\n",
    "    ax[1].legend()\n",
    "    ax[2].plot(y_test[:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    ax[2].plot(y_test_pred[:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    ax[2].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Test Samples)')\n",
    "    ax[2].set_xlabel('Sample Index')\n",
    "    ax[2].set_ylabel(target_col)\n",
    "    ax[2].legend()\n",
    "\n",
    "    ax[3].plot(y_train[:200], label=f'Actual ' + target_col, color='blue', alpha=0.7)\n",
    "    ax[3].plot(y_train_pred[:200], label='Predicted ' + target_col, color='red', linestyle='--', alpha=0.7)\n",
    "    ax[3].set_title('Random Forest: Actual vs Predicted Solar Output (First 200 Training Samples)')\n",
    "    ax[3].set_xlabel('Sample Index')\n",
    "    ax[3].set_ylabel\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a contour map of month vs hour showing residuals\n",
    "# Visualize error patterns across different times of year and day\n",
    "\n",
    "def plot_residuals_contour(y_true, y_pred, month_sin, hour_sin, title, month_cos=None, hour_cos=None):\n",
    "    \"\"\"\n",
    "    Plot residuals as a contour map over month of year and hour of day.\n",
    "    \n",
    "    Args:\n",
    "        y_true, y_pred: actual and predicted values\n",
    "        month_sin, hour_sin: sin-encoded month and hour values (pandas Series or numpy arrays)\n",
    "        title: plot title\n",
    "        month_cos, hour_cos: optional cosine-encoded month and hour for accurate inversion\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    residuals = (y_true - y_pred).ravel()\n",
    "    \n",
    "    # Convert Series to numpy arrays if needed\n",
    "    if hasattr(month_sin, 'values'):\n",
    "        month_sin = month_sin.values\n",
    "    if hasattr(hour_sin, 'values'):\n",
    "        hour_sin = hour_sin.values\n",
    "    month_sin = np.asarray(month_sin).ravel()\n",
    "    hour_sin = np.asarray(hour_sin).ravel()\n",
    "    \n",
    "    if month_cos is not None and hasattr(month_cos, 'values'):\n",
    "        month_cos = month_cos.values\n",
    "    if hour_cos is not None and hasattr(hour_cos, 'values'):\n",
    "        hour_cos = hour_cos.values\n",
    "    if month_cos is not None:\n",
    "        month_cos = np.asarray(month_cos).ravel()\n",
    "    if hour_cos is not None:\n",
    "        hour_cos = np.asarray(hour_cos).ravel()\n",
    "    \n",
    "    # Recover month (1-12) and hour (0-23) from sin/cos if available, else approximate from sin only\n",
    "    if month_cos is not None and hour_cos is not None:\n",
    "        # atan2 gives angles in [-pi, pi]; shift to [0, 2*pi]\n",
    "        month_angle = (np.arctan2(month_sin, month_cos) + 2 * np.pi) % (2 * np.pi)\n",
    "        hour_angle = (np.arctan2(hour_sin, hour_cos) + 2 * np.pi) % (2 * np.pi)\n",
    "        month = (month_angle / (2 * np.pi)) * 12  # 0..12\n",
    "        hour = (hour_angle / (2 * np.pi)) * 24    # 0..24\n",
    "    else:\n",
    "        # Fallback (ambiguous): use arcsin to map to [0, 1] then scale\n",
    "        month = (np.arcsin(np.clip(month_sin, -0.999, 0.999)) + np.pi / 2) / (2 * np.pi) * 12\n",
    "        hour = (np.arcsin(np.clip(hour_sin, -0.999, 0.999)) + np.pi / 2) / (2 * np.pi) * 24\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    contour = plt.tricontourf(month, hour, residuals, levels=15, cmap='RdBu_r')\n",
    "    plt.colorbar(contour, label='Residuals (Actual - Predicted)')\n",
    "    plt.title(f\"Residual Error Patterns - {title}\", fontsize=13)\n",
    "    plt.xlabel(\"Month of Year (1-12)\", fontsize=11)\n",
    "    plt.ylabel(\"Hour of Day (0-23)\", fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ensure required variables are available before plotting\n",
    "if 'y_test' not in locals() or 'y_test_pred' not in locals():\n",
    "    print(\"Error: y_test and y_test_pred are not defined. Please run the model training and prediction cells first.\")\n",
    "else:\n",
    "    # Plot contour maps for test set\n",
    "    plot_residuals_contour(\n",
    "        y_test,\n",
    "        y_test_pred,\n",
    "        df_daytime_test['Month_Sin'],\n",
    "        df_daytime_test['HourOfDay_Sin'],\n",
    "        \"Testing Set (Target)\",\n",
    "        month_cos=df_daytime_test.get('Month_Cos'),\n",
    "        hour_cos=df_daytime_test.get('HourOfDay_Cos')\n",
    "    )\n",
    "    plot_residuals_contour(\n",
    "        y_test_pvw,\n",
    "        y_test_pvw_pred,\n",
    "        df_daytime_test['Month_Sin'],\n",
    "        df_daytime_test['HourOfDay_Sin'],\n",
    "        \"Testing Set (PV(W))\",\n",
    "        month_cos=df_daytime_test.get('Month_Cos'),\n",
    "        hour_cos=df_daytime_test.get('HourOfDay_Cos')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4c553",
   "metadata": {},
   "source": [
    "This is too to investigate if using the media as an alternative to mean gives a beter result.\n",
    "\n",
    "\n",
    "Note: Gemini Prompt to generate the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f4fbe",
   "metadata": {},
   "source": [
    "Write results to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/svr_regressor_hourly_test_metrics.csv', 'a') as f:\n",
    "    # if this is first line write header\n",
    "    if os.stat(f'results/svr_regressor_hourly_test_metrics.csv').st_size == 0:\n",
    "        header = ['Model', 'Test No', 'Target Column',\n",
    "                  'Test Name', 'Test RMSE', 'Test MAE', 'Test R2', 'Test N-RMSE', 'Test N-MAE','Test N-RMSE %', 'Test N-MAE %', 'Test Accuracy',\n",
    "                  'Train RMSE', 'Train MAE', 'Train R2', 'Train N-RMSE', 'Train N-MAE', 'Train Accuracy','Train N-RMSE %', 'Train N-MAE %', \n",
    "                  'Test PV(W) RMSE', 'Test PV(W) MAE', 'Test PV(W) R2', 'Test PV(W) N-RMSE', 'Test PV(W) N-MAE','Test PV(W) N-RMSE %', 'Test PV(W) N-MAE %', 'Test PV(W) Accuracy',\n",
    "                  'Train PV(W) RMSE', 'Train PV(W) MAE', 'Train PV(W) R2', 'Train PV(W) N-RMSE', 'Train PV(W) N-MAE', 'Train PV(W) Accuracy','Train PV(W) N-RMSE %', 'Train PV(W) N-MAE %',\n",
    "                  'Notes', 'Feature Columns']\n",
    "        f.write(','.join(header) + '\\n')\n",
    "    line=[]\n",
    "    line.append(\"SVR Regressor Hourly\")\n",
    "    line.append(test_no)\n",
    "    line.append(test_name)\n",
    "    line.append(f\"{target_col}\")\n",
    "    line.append(f\"{test_rmse:.2f}\")\n",
    "    line.append(f\"{test_mae:.2f}\")\n",
    "    line.append(f\"{test_r2:.4f}\")\n",
    "    line.append(f\"{test_n_rmse:.4f}\")\n",
    "    line.append(f\"{test_n_mae:.4f}\")\n",
    "    line.append(f\"{test_n_rmse*100:.4f}\"  )\n",
    "    line.append(f\"{test_n_mae*100:.4f}\"  )\n",
    "    line.append(f\"{test_accuracy:.4f}\")\n",
    "    line.append(f\"{train_rmse:.2f}\")\n",
    "    line.append(f\"{train_mae:.2f}\")\n",
    "    line.append(f\"{train_r2:.4f}\")\n",
    "    line.append(f\"{train_n_rmse:.4f}\")\n",
    "    line.append(f\"{train_n_mae:.4f}\")\n",
    "    line.append(f\"{train_n_rmse*100:.4f}\"  )\n",
    "    line.append(f\"{train_n_mae*100:.4f}\"  )\n",
    "    line.append(f\"{train_accuracy:.4f}\")\n",
    "    line.append(f\"{test_rmse_pvw:.2f}\")\n",
    "    line.append(f\"{test_mae_pvw:.2f}\")\n",
    "    line.append(f\"{test_r2_pvw:.4f}\")\n",
    "    line.append(f\"{test_n_rmse_pvw:.4f}\")\n",
    "    line.append(f\"{test_n_mae_pvw:.4f}\")\n",
    "    line.append(f\"{test_n_rmse_pvw*100:.4f}\"  )\n",
    "    line.append(f\"{test_n_mae_pvw*100:.4f}\"  )\n",
    "    line.append(f\"{test_accuracy_pvw:.4f}\")\n",
    "    line.append(f\"{train_rmse_pvw:.2f}\")\n",
    "    line.append(f\"{train_mae_pvw:.2f}\")\n",
    "    line.append(f\"{train_r2_pvw:.4f}\")\n",
    "    line.append(f\"{train_n_rmse_pvw:.4f}\")\n",
    "    line.append(f\"{train_n_mae_pvw:.4f}\")\n",
    "    line.append(f\"{train_n_rmse_pvw*100:.4f}\"  )\n",
    "    line.append(f\"{train_n_mae_pvw*100:.4f}\"  )\n",
    "    line.append(f\"{train_accuracy_pvw:.4f}\")\n",
    "    line.append(f\"{notes if 'notes' in locals() else ''}\")\n",
    "    line.append(f\"feature_cols: {':'.join(feature_cols)}\")\n",
    "    f.write(','.join(line) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
