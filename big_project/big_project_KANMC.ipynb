{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Requires: pip install pykan\n",
    "\n",
    "import os\n",
    "#import seaborn as sns\n",
    "import datetime as datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf102a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the current path of the notebook\n",
    "notebook_path = os.path.abspath(\"big_project.ipynb\")\n",
    "notebook_dir = os.path.dirname(notebook_path).replace('\\\\', '/')\n",
    "print(\"Current notebook directory:\", notebook_dir)\n",
    "HOME_DIR = f'{notebook_dir}'\n",
    "DATA_DIR = f'{HOME_DIR}/data/'\n",
    "MODEL_DIR = f'{HOME_DIR}/model/'\n",
    "print(\"Data directory set to:\", DATA_DIR)\n",
    "RAW_DATA_DIR = f'{DATA_DIR}/raw_data/'\n",
    "TRAIN_DATA_DIR = f'{DATA_DIR}/training_data/'\n",
    "SQL_DB_PATH = f'{DATA_DIR}/db_sqlite/'\n",
    "SQL_DB_FILE = f'{SQL_DB_PATH}/big_project_db.sqlite3'\n",
    "BACKUP_FILE_TYPE = 'feather'  # Options: 'csv', 'feather', 'parquet'\n",
    "\n",
    "# Meteostat setup\n",
    "METEOSTAT_CACHE_DIR = f'{DATA_DIR}/meteostat_cache/'\n",
    "SOLAR_SITE_POSITION = (53.6985, -6.2080)  # Bettystown, Ireland\n",
    "LATITUDE, LONGITUDE = SOLAR_SITE_POSITION\n",
    "WEATHER_START_DATE = datetime.datetime(2024, 1, 1)\n",
    "WEATHER_END_DATE = datetime.datetime.now()\n",
    "# Solar panel configuration \n",
    "# Determined this using gemini and google maps measurements\n",
    "ROOF_PANE_I_ANGLE = 30  # degrees\n",
    "ROOF_PANE_II_ANGLE = 30  # degrees\n",
    "ROOF_PANE_I_AZIMUTH = 65  # degrees ( East-South-East)\n",
    "ROOF_PANE_II_AZIMUTH = 245  # degrees ( West-South-West)\n",
    "ROOF_PANE_I_COUNT = 7\n",
    "ROOF_PANE_II_COUNT = 12\n",
    "SOLAR_PANEL_POWER_RATING_W = 440  # Watts per panel\n",
    "TOTAL_SOLAR_PANE_I_CAPACITY_W = ROOF_PANE_I_COUNT * SOLAR_PANEL_POWER_RATING_W\n",
    "TOTAL_SOLAR_PANE_II_CAPACITY_W = ROOF_PANE_II_COUNT * SOLAR_PANEL_POWER_RATING_W\n",
    "TOTAL_SOLAR_CAPACITY_W = TOTAL_SOLAR_PANE_I_CAPACITY_W + TOTAL_SOLAR_PANE_II_CAPACITY_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fcdff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_nighlty_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f27006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_hourly = pd.read_feather(f\"{TRAIN_DATA_DIR}/hourly_solar_full_data.feather\")\n",
    "\n",
    "# Remove all rows where Clear sky GHI is less than or equal to 50\n",
    "df_merge_hourly = df_merge_hourly[df_merge_hourly['Clear sky GHI'] > hourly_nighlty_threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "level1_features = [level for level in df_merge_hourly.columns.tolist() if level.startswith('level1_')]\n",
    "level2_features = [level for level in df_merge_hourly.columns.tolist() if level.startswith('level2_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(pd.DataFrame({\"Columns\": df_merge_hourly.columns, \"Data Types\": df_merge_hourly.dtypes}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_cols = []\n",
    "# Columns: ['index', 'DateTime', 'PV(W)', 'Temperature(C)', 'Humidity(%)', 'Sunshine Duration', 'Condition Code', 'Precipitation(mm)', 'Dew Point(C)', 'Wind Direction(deg)', 'Wind Speed(m/s)', 'Wind Gust(m/s)', 'Pressure(hPa)', 'Snow Depth(cm)', 'level1_clear', 'level1_cloudy', 'level1_fair', 'level1_fog', 'level1_freezing_rain', 'level1_heavy_rain', 'level1_heavy_rain_shower', 'level1_heavy_sleet', 'level1_light_rain', 'level1_overcast', 'level1_rain', 'level1_rain_shower', 'level1_sleet', 'level1_sleet_shower', 'level1_thunderstorm', 'level2_good_visibility', 'level2_moderate_visibility', 'level2_poor_visibility', 'level2_precipitation', 'level2_severe_weather', '# Observation period', 'TOA', 'Clear sky GHI', 'Clear sky BHI', 'Clear sky DHI', 'Clear sky BNI', 'GHI', 'BHI', 'DHI', 'BNI', 'Reliability,', 'Time', 'Date', 'POA_Pane_I(W/m^2)', 'POA_Pane_II(W/m^2)', 'POAC_Pane_I(W/m^2)', 'POAC_Pane_II(W/m^2)', 'Power_Pane_I(W)', 'Power_Pane_II(W)', 'Power_ClearSky_Pane_I(W)', 'Power_ClearSky_Pane_II(W)', 'Total_Power_Output(W)', 'Total_Power_ClearSky_Output(W)', 'WeekOfYear', 'Month_Sin', 'DayOfYear_Sin', 'HourOfDay_Sin']\n",
    "feature_cols = []\n",
    "test_no=\"999\"\n",
    "# Define target column\n",
    "\n",
    "target_col = 'PV(W)'\n",
    "# Kan Prefers Clearsky_Index\n",
    "#target_col = 'Clearsky_Index'\n",
    "#target_col = 'PV(W)_error'\n",
    "#target_col = 'PV(W)_error_index'\n",
    "#\n",
    "test_name=f\"Optimal Features  No Level 2 and No Clearsky - Target {target_col}\"\n",
    "notes=\"This is the best combination of features exclude level 2 and no clearsky weather features\"\n",
    "\n",
    "# Put change here to add more features\n",
    "feature_cols.append('Temperature(C)')\n",
    "feature_cols.append('Humidity(%)')\n",
    "feature_cols.append('Sunshine Duration')\n",
    "#feature_cols.append('Condition Code')\n",
    "feature_cols.append('Precipitation(mm)')\n",
    "feature_cols.append('Dew Point(C)')\n",
    "feature_cols.append('Wind Direction(deg)')\n",
    "feature_cols.append('Wind Speed(m/s)')\n",
    "feature_cols.append('Wind Gust(m/s)')\n",
    "feature_cols.append('Pressure(hPa)')\n",
    "#feature_cols.append('Snow Depth(cm)')\n",
    "feature_cols.append('Wind Cooling')\n",
    "#  level1_features\n",
    "#feature_cols.append('# Observation period')\n",
    "#feature_cols.append('TOA')\n",
    "#feature_cols.append('Clear sky GHI')\n",
    "#feature_cols.append('Clear sky BHI')\n",
    "#feature_cols.append('Clear sky DHI')\n",
    "#feature_cols.append('Clear sky BNI')\n",
    "# Relate to target #feature_cols.append('GHI')\n",
    "# Relate to target #feature_cols.append('BHI')\n",
    "# Relate to target #feature_cols.append('DHI')\n",
    "# Relate to target #feature_cols.append('BNI')\n",
    "# String ignore feature_cols.append('Reliability,')\n",
    "# Relate to target #feature_cols.append('POA_Pane_I(W/m^2)')\n",
    "# Relate to target #feature_cols.append('POA_Pane_II(W/m^2)')\n",
    "# Relate to target #feature_cols.append('POAC_Pane_I(W/m^2)')\n",
    "# Relate to target #feature_cols.append('POAC_Pane_II(W/m^2)')\n",
    "# Relate to target #feature_cols.append('Power_Pane_I(W)')\n",
    "# Relate to target #feature_cols.append('Power_Pane_II(W)')\n",
    "feature_cols.append('Power_ClearSky_Pane_I(W)')\n",
    "feature_cols.append('Power_ClearSky_Pane_II(W)')\n",
    "# Relate to target #feature_cols.append('Total_Power_Output(W)')\n",
    "feature_cols.append('Total_Power_ClearSky_Output(W)')\n",
    "#feature_cols.append('WeekOfYear')\n",
    "feature_cols.append('Month_Sin')\n",
    "feature_cols.append('DayOfYear_Sin')\n",
    "feature_cols.append('HourOfDay_Sin')\n",
    "feature_cols.append('Month_Cos')\n",
    "feature_cols.append('DayOfYear_Cos')\n",
    "feature_cols.append('HourOfDay_Cos')\n",
    "#  level2_features\n",
    "feature_cols += level2_features\n",
    "#  level1_features\n",
    "#feature_cols += level1_features\n",
    "\n",
    "print(f\"\\nTesting Random Forest Regressor with target: {target_col} and features: {feature_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fdc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9558cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 1. Prepare Data (Using your winning \"Error\" target)\n",
    "# ==========================================\n",
    "\n",
    "# Assuming 'df' is your DataFrame and we want to predict 'PV_Error'\n",
    "# Define your features (X) and target (y)\n",
    "features = feature_cols\n",
    "target_col = target_col\n",
    "\n",
    "# Drop NaNs\n",
    "model_df = df_merge_hourly.dropna(subset=features + [target_col])\n",
    "X = model_df[features].values\n",
    "y = model_df[target_col].values.reshape(-1, 1)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize (Neural Networks LOVES scaled data)\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Create dataset dictionary for pykan\n",
    "# pykan expects keys: 'train_input', 'train_label', 'test_input', 'test_label'\n",
    "dataset = {}\n",
    "dataset['train_input'] = torch.from_numpy(X_train_scaled).float()\n",
    "dataset['train_label'] = torch.from_numpy(y_train).float()\n",
    "dataset['test_input'] = torch.from_numpy(X_test_scaled).float()\n",
    "dataset['test_label'] = torch.from_numpy(y_test).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3222d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81463622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. Define & Train the KAN\n",
    "# ==========================================\n",
    "\n",
    "# Initialize KAN\n",
    "# width: [input_dim, hidden_dim, output_dim]\n",
    "# grid: granularity of the spline grid (higher = more detailed but prone to overfitting)\n",
    "# k: order of the spline (k=3 is cubic)\n",
    "input_dim = X_train_scaled\n",
    "print(f\"Input dimension for KAN: {input_dim}\")\n",
    "\n",
    "model = kan.KAN(width=[input_dim,8, 1],\n",
    "                 grid=12, \n",
    "                 k=3, \n",
    "                 seed=42)\n",
    "\n",
    "print(\"Starting KAN Training (using LBFGS optimizer)...\")\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "print(f\"Training samples: {X_train_scaled.shape[0]}\")\n",
    "print(f\"Test samples: {X_test_scaled.shape[0]}\")\n",
    "\n",
    "# Train the KAN model using the dataset dictionary\n",
    "print(\"\\nTraining KAN model with LBFGS optimizer...\")\n",
    "results = model.fit(dataset, \n",
    "                    opt='LBFGS', \n",
    "                    steps=40, \n",
    "                    lamb=0.005, \n",
    "                    lamb_entropy=0.01)\n",
    "\n",
    "print(\"\\n✓ KAN Training Complete!\")\n",
    "print(f\"Training iterations completed: 50\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab1ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================\n",
    "# Get Predictions from the Model\n",
    "# =========================================================\n",
    "\n",
    "# Get predictions on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\ty_pred_tensor = model(dataset['test_input'])\n",
    "y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "# =========================================================\n",
    "# Get the Clear Sky values for your test set\n",
    "# =========================================================\n",
    "# Find the index of 'Clear sky GHI' in feature_cols\n",
    "clearsky_index = feature_cols.index('Total_Power_ClearSky_Output(W)')\n",
    "\n",
    "# Extract the Clear Sky GHI values from X_test_scaled\n",
    "# We need to inverse-transform to get the actual values\n",
    "clearsky_scaled = X_test_scaled[:, clearsky_index].reshape(-1, 1)\n",
    "\n",
    "# Create a dummy array with zeros and replace the column with our clearsky values\n",
    "dummy_for_inverse = np.zeros((X_test_scaled.shape[0], X_train.shape[1]))\n",
    "dummy_for_inverse[:, clearsky_index] = clearsky_scaled.flatten()\n",
    "\n",
    "# Inverse transform to get actual values (only the clearsky column matters)\n",
    "clearsky_ref = scaler_X.inverse_transform(dummy_for_inverse)[:, clearsky_index].reshape(-1, 1)\n",
    "\n",
    "# =========================================================\n",
    "# Reconstruct Total Values\n",
    "# =========================================================\n",
    "# Your model predicts Clearsky_Index (a normalized error)\n",
    "# To get actual watts, you multiply by Clear Sky GHI\n",
    "\n",
    "y_test_total = y_test * clearsky_ref\n",
    "y_pred_total = y_pred * clearsky_ref\n",
    "\n",
    "# Physics Clamp (Force negatives to 0)\n",
    "y_pred_total = np.clip(y_pred_total, 0, None)\n",
    "y_test_total = np.clip(y_test_total, 0, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a2f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Calculate Metrics\n",
    "# =========================================================\n",
    "\n",
    "# 1. Calculate MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test_total, y_pred_total)\n",
    "\n",
    "# 2. Calculate RMSE (Root Mean Squared Error)\n",
    "mse = mean_squared_error(y_test_total, y_pred_total)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# 3. Calculate R^2 Score\n",
    "r2 = r2_score(y_test_total, y_pred_total)\n",
    "\n",
    "# 4. Normalized Metrics\n",
    "capacity = y_test_total.max()\n",
    "n_mae = (mae / capacity) * 100\n",
    "n_rmse = (rmse / capacity) * 100\n",
    "\n",
    "print(f\"MAE:  {mae:.2f} W\")\n",
    "print(f\"RMSE: {rmse:.2f} W\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "print(f\"N-MAE: {n_mae:.2f}%\")\n",
    "print(f\"N-RMSE: {n_rmse:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f6c1df",
   "metadata": {},
   "source": [
    "__Save Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed2ac21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec891fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.saveckpt(f\"{MODEL_DIR}/kan_model_target.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
