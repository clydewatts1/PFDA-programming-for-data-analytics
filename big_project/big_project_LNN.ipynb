{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liquid Neural Network (CfC) for Solar Power Prediction\n",
    "\n",
    "This notebook implements a Liquid Neural Network using the ncps library (Closed-form Continuous-time) to predict solar output.\n",
    "\n",
    "## Approach:\n",
    "1. Load existing DataFrame with weather and solar data\n",
    "2. Create sliding window sequences for RNN input\n",
    "3. Build CfC-based model\n",
    "4. Train with MSELoss and Adam optimizer\n",
    "5. Predict PV(W)_error and reconstruct final PV(W)\n",
    "6. Evaluate with RMSE and R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import ncps\n",
    "from ncps.torch import CfC\n",
    "from ncps.wirings import AutoNCP\n",
    "import os\n",
    "import datetime\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths and configuration\n",
    "notebook_path = os.path.abspath(\"big_project.ipynb\")\n",
    "notebook_dir = os.path.dirname(notebook_path).replace('\\\\', '/')\n",
    "print(\"Current notebook directory:\", notebook_dir)\n",
    "HOME_DIR = f'{notebook_dir}'\n",
    "DATA_DIR = f'{HOME_DIR}/data/'\n",
    "MODEL_DIR = f'{HOME_DIR}/model/'\n",
    "TRAIN_DATA_DIR = f'{DATA_DIR}/training_data/'\n",
    "print(\"Data directory set to:\", DATA_DIR)\n",
    "print(\"Model directory set to:\", MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "df_train = pd.read_feather(f\"{TRAIN_DATA_DIR}/hourly_solar_training_data.feather\")\n",
    "df_test = pd.read_feather(f\"{TRAIN_DATA_DIR}/hourly_solar_testing_data.feather\")\n",
    "\n",
    "print(f\"Training data shape: {df_train.shape}\")\n",
    "print(f\"Testing data shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (weather features)\n",
    "feature_cols = [\n",
    "    'Temperature(C)',\n",
    "    'Humidity(%)',\n",
    "    'Sunshine Duration',\n",
    "    'Precipitation(mm)',\n",
    "    'Dew Point(C)',\n",
    "    'Wind Direction(deg)',\n",
    "    'Wind Speed(m/s)',\n",
    "    'Pressure(hPa)',\n",
    "    'Wind Cooling',\n",
    "    'Total_Power_ClearSky_Output(W)',\n",
    "    'Month_Sin',\n",
    "    'DayOfYear_Sin',\n",
    "    'HourOfDay_Sin',\n",
    "    'Month_Cos',\n",
    "    'DayOfYear_Cos',\n",
    "    'HourOfDay_Cos',\n",
    "    'Dew Point(C)_Lag1',\n",
    "    'Temp_Lag1',\n",
    "    'Humidity_Lag1',\n",
    "    'WindSpeed_Lag1',\n",
    "    'Dew Point(C)_Lag24',\n",
    "    'Temp_Lag24',\n",
    "    'Humidity_Lag24',\n",
    "    'WindSpeed_Lag24',\n",
    "    'Total_Power_ClearSky_Output(W)_Lag1',\n",
    "    'Total_Power_ClearSky_Output(W)_Lag24'\n",
    "]\n",
    "\n",
    "# Add level 2 features\n",
    "level2_features = [col for col in df_train.columns if col.startswith('level2_')]\n",
    "feature_cols += level2_features\n",
    "\n",
    "# Target column\n",
    "target_col = 'PV(W)_error'  # This is the residual: Actual PV - ClearSky Output\n",
    "\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Target column: {target_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sliding window sequences for RNN\n",
    "def create_sequences(data, target, sequence_length=24):\n",
    "    \"\"\"\n",
    "    Convert tabular data into 3D sequences for RNN input.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame or array of features\n",
    "        target: Series or array of target values\n",
    "        sequence_length: Number of time steps in each sequence\n",
    "    \n",
    "    Returns:\n",
    "        X_seq: Array of shape (num_sequences, sequence_length, num_features)\n",
    "        y_seq: Array of shape (num_sequences,)\n",
    "        clearsky_seq: Array of clearsky values for inverse transform\n",
    "    \"\"\"\n",
    "    X = data.values if isinstance(data, pd.DataFrame) else data\n",
    "    y = target.values if isinstance(target, pd.Series) else target\n",
    "    \n",
    "    # Get clearsky output for inverse transformation\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        clearsky_idx = data.columns.get_loc('Total_Power_ClearSky_Output(W)')\n",
    "        clearsky = X[:, clearsky_idx]\n",
    "    else:\n",
    "        clearsky = X[:, 9]  # Index of Total_Power_ClearSky_Output(W)\n",
    "    \n",
    "    num_sequences = len(X) - sequence_length + 1\n",
    "    X_seq = np.zeros((num_sequences, sequence_length, X.shape[1]))\n",
    "    y_seq = np.zeros(num_sequences)\n",
    "    clearsky_seq = np.zeros(num_sequences)\n",
    "    \n",
    "    for i in range(num_sequences):\n",
    "        X_seq[i] = X[i:i + sequence_length]\n",
    "        y_seq[i] = y[i + sequence_length - 1]  # Predict the target at the end of the sequence window\n",
    "        clearsky_seq[i] = clearsky[i + sequence_length - 1]\n",
    "    \n",
    "    return X_seq, y_seq, clearsky_seq\n",
    "\n",
    "print(\"Sequence creation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "SEQUENCE_LENGTH = 24  # 24 hours of historical data\n",
    "\n",
    "# Extract features and target\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[target_col]\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[target_col]\n",
    "\n",
    "print(\"Original shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features normalized with StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "X_train_seq, y_train_seq, clearsky_train = create_sequences(\n",
    "    X_train, y_train, SEQUENCE_LENGTH\n",
    ")\n",
    "X_test_seq, y_test_seq, clearsky_test = create_sequences(\n",
    "    X_test, y_test, SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "print(\"\\nSequence shapes:\")\n",
    "print(f\"X_train_seq: {X_train_seq.shape}\")\n",
    "print(f\"y_train_seq: {y_train_seq.shape}\")\n",
    "print(f\"X_test_seq: {X_test_seq.shape}\")\n",
    "print(f\"y_test_seq: {y_test_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling to sequences\n",
    "# Reshape to 2D for scaling, then back to 3D\n",
    "n_train = X_train_seq.shape[0]\n",
    "n_test = X_test_seq.shape[0]\n",
    "\n",
    "X_train_seq_2d = X_train_seq.reshape(-1, X_train_seq.shape[2])\n",
    "X_test_seq_2d = X_test_seq.reshape(-1, X_test_seq.shape[2])\n",
    "\n",
    "X_train_seq_scaled = scaler.transform(X_train_seq_2d).reshape(n_train, SEQUENCE_LENGTH, -1)\n",
    "X_test_seq_scaled = scaler.transform(X_test_seq_2d).reshape(n_test, SEQUENCE_LENGTH, -1)\n",
    "\n",
    "print(\"Sequences normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_seq_scaled).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train_seq).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test_seq_scaled).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test_seq).to(device)\n",
    "\n",
    "print(\"Data converted to PyTorch tensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CfC-based Liquid Neural Network model\n",
    "class LiquidNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, output_size=1):\n",
    "        \"\"\"\n",
    "        Liquid Neural Network using CfC (Closed-form Continuous-time) layer.\n",
    "        \n",
    "        Architecture: Input -> CfC Layer -> Output\n",
    "        \n",
    "        Args:\n",
    "            input_size: Number of input features\n",
    "            hidden_size: Number of hidden units in CfC layer\n",
    "            output_size: Number of output values (1 for regression)\n",
    "        \"\"\"\n",
    "        super(LiquidNeuralNetwork, self).__init__()\n",
    "        \n",
    "        # Create wiring for the CfC network\n",
    "        # AutoNCP automatically creates a sparse wiring architecture\n",
    "        # that maps directly to the output dimension\n",
    "        wiring = AutoNCP(hidden_size, output_size)\n",
    "        \n",
    "        # CfC layer - the core of the Liquid Neural Network\n",
    "        # This already includes the output projection\n",
    "        self.cfc = CfC(input_size, wiring, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, sequence_length, input_size)\n",
    "        \n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size,)\n",
    "        \"\"\"\n",
    "        # Pass through CfC layer\n",
    "        # Returns output for all time steps: (batch, seq_len, output_dim)\n",
    "        cfc_out, _ = self.cfc(x)\n",
    "        \n",
    "        # Take the output from the last time step\n",
    "        # Shape: (batch, output_dim)\n",
    "        last_output = cfc_out[:, -1, :]\n",
    "        \n",
    "        # Squeeze to get shape (batch,) for single output\n",
    "        return last_output.squeeze()\n",
    "\n",
    "print(\"LiquidNeuralNetwork model class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "input_size = X_train_seq_scaled.shape[2]\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "\n",
    "model = LiquidNeuralNetwork(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "print(f\"Model initialized with:\")\n",
    "print(f\"  Input size: {input_size}\")\n",
    "print(f\"  Hidden size: {hidden_size}\")\n",
    "print(f\"  Output size: {output_size}\")\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Loss function: MSELoss\")\n",
    "print(\"Optimizer: Adam (lr=0.001)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training for {num_epochs} epochs with batch size {batch_size}\")\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(test_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_pred = model(X_train_tensor).cpu().numpy()\n",
    "    y_test_pred = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "y_train_actual = y_train_seq\n",
    "y_test_actual = y_test_seq\n",
    "\n",
    "print(\"Predictions generated\")\n",
    "print(f\"Train predictions shape: {y_train_pred.shape}\")\n",
    "print(f\"Test predictions shape: {y_test_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform: Add predictions back to Total_Power_ClearSky_Output(W)\n",
    "# PV(W) = PV(W)_error + Total_Power_ClearSky_Output(W)\n",
    "\n",
    "y_train_pvw_pred = y_train_pred + clearsky_train\n",
    "y_train_pvw_actual = y_train_actual + clearsky_train\n",
    "\n",
    "y_test_pvw_pred = y_test_pred + clearsky_test\n",
    "y_test_pvw_actual = y_test_actual + clearsky_test\n",
    "\n",
    "# Clip negative predictions to 0 (solar power cannot be negative)\n",
    "y_train_pvw_pred = np.clip(y_train_pvw_pred, 0, None)\n",
    "y_test_pvw_pred = np.clip(y_test_pvw_pred, 0, None)\n",
    "\n",
    "print(\"Inverse transformation completed\")\n",
    "print(\"Negative predictions clipped to 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate RMSE, MAE, R2, and normalized metrics.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Normalized metrics\n",
    "    normalization_factor = np.max(y_true) - np.min(y_true)\n",
    "    n_rmse = rmse / normalization_factor\n",
    "    n_mae = mae / normalization_factor\n",
    "    \n",
    "    # Accuracy score\n",
    "    accuracy_score = 1 - (mae / np.mean(y_true))\n",
    "    \n",
    "    return rmse, mae, r2, n_rmse, n_mae, accuracy_score\n",
    "\n",
    "# Calculate metrics for PV(W)_error predictions\n",
    "train_rmse, train_mae, train_r2, train_n_rmse, train_n_mae, train_accuracy = calculate_metrics(\n",
    "    y_train_actual, y_train_pred\n",
    ")\n",
    "test_rmse, test_mae, test_r2, test_n_rmse, test_n_mae, test_accuracy = calculate_metrics(\n",
    "    y_test_actual, y_test_pred\n",
    ")\n",
    "\n",
    "# Calculate metrics for reconstructed PV(W)\n",
    "train_rmse_pvw, train_mae_pvw, train_r2_pvw, train_n_rmse_pvw, train_n_mae_pvw, train_accuracy_pvw = calculate_metrics(\n",
    "    y_train_pvw_actual, y_train_pvw_pred\n",
    ")\n",
    "test_rmse_pvw, test_mae_pvw, test_r2_pvw, test_n_rmse_pvw, test_n_mae_pvw, test_accuracy_pvw = calculate_metrics(\n",
    "    y_test_pvw_actual, y_test_pvw_pred\n",
    ")\n",
    "\n",
    "print(\"Metrics calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metrics for PV(W)_error\n",
    "mk_string = \"\"\"| Metric       | Training Set        | Testing Set         |\n",
    "|--------------|---------------------|---------------------|\n",
    "| RMSE         | {:.2f}              | {:.2f}              |\n",
    "| MAE          | {:.2f}              | {:.2f}              |\n",
    "| R2           | {:.4f}              | {:.4f}              |\n",
    "| N-RMSE (%)   | {:.4f}              | {:.4f}              |\n",
    "| N-MAE (%)    | {:.4f}              | {:.4f}              |\n",
    "| Accuracy (%) | {:.4f}              | {:.4f}              |\"\"\".format(\n",
    "    train_rmse, test_rmse,\n",
    "    train_mae, test_mae,\n",
    "    train_r2, test_r2,\n",
    "    train_n_rmse*100, test_n_rmse*100,\n",
    "    train_n_mae*100, test_n_mae*100,\n",
    "    train_accuracy*100, test_accuracy*100\n",
    ")\n",
    "\n",
    "display(Markdown(f\"### Liquid Neural Network Performance Metrics - PV(W)_error\\n\" + mk_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metrics for reconstructed PV(W)\n",
    "mk_string = \"\"\"| Metric       | Training Set        | Testing Set         |\n",
    "|--------------|---------------------|---------------------|\n",
    "| RMSE         | {:.2f}              | {:.2f}              |\n",
    "| MAE          | {:.2f}              | {:.2f}              |\n",
    "| R2           | {:.4f}              | {:.4f}              |\n",
    "| N-RMSE (%)   | {:.4f}              | {:.4f}              |\n",
    "| N-MAE (%)    | {:.4f}              | {:.4f}              |\n",
    "| Accuracy (%) | {:.4f}              | {:.4f}              |\"\"\".format(\n",
    "    train_rmse_pvw, test_rmse_pvw,\n",
    "    train_mae_pvw, test_mae_pvw,\n",
    "    train_r2_pvw, test_r2_pvw,\n",
    "    train_n_rmse_pvw*100, test_n_rmse_pvw*100,\n",
    "    train_n_mae_pvw*100, test_n_mae_pvw*100,\n",
    "    train_accuracy_pvw*100, test_accuracy_pvw*100\n",
    ")\n",
    "\n",
    "display(Markdown(f\"### Liquid Neural Network Performance Metrics - Reconstructed PV(W)\\n\" + mk_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted for test set (PV(W))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test_pvw_actual, y_test_pvw_pred, alpha=0.5)\n",
    "plt.plot([y_test_pvw_actual.min(), y_test_pvw_actual.max()], \n",
    "         [y_test_pvw_actual.min(), y_test_pvw_actual.max()], \n",
    "         'r--', lw=2)\n",
    "plt.xlabel('Actual PV(W)')\n",
    "plt.ylabel('Predicted PV(W)')\n",
    "plt.title('Test Set: Actual vs Predicted PV(W)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test_pvw_actual - y_test_pvw_pred\n",
    "plt.scatter(y_test_pvw_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel('Predicted PV(W)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Test Set: Residual Plot')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series comparison (first 200 predictions)\n",
    "plt.figure(figsize=(14, 6))\n",
    "n_samples = min(200, len(y_test_pvw_actual))\n",
    "plt.plot(range(n_samples), y_test_pvw_actual[:n_samples], label='Actual', alpha=0.7)\n",
    "plt.plot(range(n_samples), y_test_pvw_pred[:n_samples], label='Predicted', alpha=0.7)\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('PV(W)')\n",
    "plt.title('Test Set: Time Series Comparison (First 200 predictions)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = f\"{MODEL_DIR}/liquid_neural_network_model.pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scaler': scaler,\n",
    "    'sequence_length': SEQUENCE_LENGTH,\n",
    "    'input_size': input_size,\n",
    "    'hidden_size': hidden_size,\n",
    "    'feature_cols': feature_cols,\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "summary = f\"\"\"\n",
    "## Summary\n",
    "\n",
    "### Model Architecture\n",
    "- **Type**: Liquid Neural Network (CfC - Closed-form Continuous-time)\n",
    "- **Input**: Weather features over 24-hour sliding windows\n",
    "- **Architecture**: Input ({input_size} features) -> CfC Layer ({hidden_size} units) -> Linear Head -> Output (1 value)\n",
    "- **Sequence Length**: {SEQUENCE_LENGTH} hours\n",
    "- **Training Epochs**: {num_epochs}\n",
    "- **Optimizer**: Adam (lr=0.001)\n",
    "- **Loss Function**: MSELoss\n",
    "\n",
    "### Performance on PV(W) Reconstruction\n",
    "- **Test RMSE**: {test_rmse_pvw:.2f} W\n",
    "- **Test MAE**: {test_mae_pvw:.2f} W\n",
    "- **Test R\u00b2**: {test_r2_pvw:.4f}\n",
    "- **Test Accuracy**: {test_accuracy_pvw*100:.2f}%\n",
    "\n",
    "### Key Features\n",
    "- Predicts residual error (PV(W)_error) and reconstructs final PV(W)\n",
    "- Uses continuous-time neural computation for better temporal modeling\n",
    "- Handles sequential dependencies in weather and solar data\n",
    "- Automatically clips negative predictions to ensure physical validity\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(summary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}