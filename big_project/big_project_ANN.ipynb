{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import os\n",
        "import seaborn as sns\n",
        "import datetime as datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solar Output Prediction using PyTorch Artificial Neural Network\n",
        "\n",
        "This notebook implements a simple feedforward neural network using PyTorch to predict PV(W) - Solar Output.\n",
        "Based on the approach used in `big_project_KAN.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Determine the current path of the notebook\n",
        "notebook_path = os.path.abspath(\"big_project.ipynb\")\n",
        "notebook_dir = os.path.dirname(notebook_path).replace('\\\\', '/')\n",
        "print(\"Current notebook directory:\", notebook_dir)\n",
        "HOME_DIR = f'{notebook_dir}'\n",
        "DATA_DIR = f'{HOME_DIR}/data/'\n",
        "MODEL_DIR = f'{HOME_DIR}/model/'\n",
        "print(\"Data directory set to:\", DATA_DIR)\n",
        "RAW_DATA_DIR = f'{DATA_DIR}/raw_data/'\n",
        "TRAIN_DATA_DIR = f'{DATA_DIR}/training_data/'\n",
        "SQL_DB_PATH = f'{DATA_DIR}/db_sqlite/'\n",
        "SQL_DB_FILE = f'{SQL_DB_PATH}/big_project_db.sqlite3'\n",
        "BACKUP_FILE_TYPE = 'feather'  # Options: 'csv', 'feather', 'parquet'\n",
        "\n",
        "# Meteostat setup\n",
        "METEOSTAT_CACHE_DIR = f'{DATA_DIR}/meteostat_cache/'\n",
        "SOLAR_SITE_POSITION = (53.6985, -6.2080)  # Bettystown, Ireland\n",
        "LATITUDE, LONGITUDE = SOLAR_SITE_POSITION\n",
        "WEATHER_START_DATE = datetime.datetime(2024, 1, 1)\n",
        "WEATHER_END_DATE = datetime.datetime.now()\n",
        "# Solar panel configuration \n",
        "# Determined this using gemini and google maps measurements\n",
        "ROOF_PANE_I_ANGLE = 30  # degrees\n",
        "ROOF_PANE_II_ANGLE = 30  # degrees\n",
        "ROOF_PANE_I_AZIMUTH = 65  # degrees ( East-South-East)\n",
        "ROOF_PANE_II_AZIMUTH = 245  # degrees ( West-South-West)\n",
        "ROOF_PANE_I_COUNT = 7\n",
        "ROOF_PANE_II_COUNT = 12\n",
        "SOLAR_PANEL_POWER_RATING_W = 440  # Watts per panel\n",
        "TOTAL_SOLAR_PANE_I_CAPACITY_W = ROOF_PANE_I_COUNT * SOLAR_PANEL_POWER_RATING_W\n",
        "TOTAL_SOLAR_PANE_II_CAPACITY_W = ROOF_PANE_II_COUNT * SOLAR_PANEL_POWER_RATING_W\n",
        "TOTAL_SOLAR_CAPACITY_W = TOTAL_SOLAR_PANE_I_CAPACITY_W + TOTAL_SOLAR_PANE_II_CAPACITY_W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hourly_nighlty_threshold = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_merge_hourly = pd.read_feather(f\"{TRAIN_DATA_DIR}/hourly_solar_full_data.feather\")\n",
        "\n",
        "# Remove all rows where Clear sky GHI is less than or equal to 50\n",
        "df_merge_hourly = df_merge_hourly[df_merge_hourly['Clear sky GHI'] > hourly_nighlty_threshold]\n",
        "\n",
        "print(f\"Data loaded: {df_merge_hourly.shape[0]} rows, {df_merge_hourly.shape[1]} columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "level1_features = [level for level in df_merge_hourly.columns.tolist() if level.startswith('level1_')]\n",
        "level2_features = [level for level in df_merge_hourly.columns.tolist() if level.startswith('level2_')]\n",
        "\n",
        "print(f\"Level 1 features: {len(level1_features)}\")\n",
        "print(f\"Level 2 features: {len(level2_features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define target column\n",
        "target_col = 'PV(W)'\n",
        "\n",
        "# Define features - same as KAN notebook\n",
        "feature_cols = []\n",
        "feature_cols.append('Temperature(C)')\n",
        "feature_cols.append('Humidity(%)')\n",
        "feature_cols.append('Sunshine Duration')\n",
        "feature_cols.append('Precipitation(mm)')\n",
        "feature_cols.append('Dew Point(C)')\n",
        "feature_cols.append('Wind Direction(deg)')\n",
        "feature_cols.append('Wind Speed(m/s)')\n",
        "feature_cols.append('Wind Gust(m/s)')\n",
        "feature_cols.append('Pressure(hPa)')\n",
        "feature_cols.append('Wind Cooling')\n",
        "feature_cols.append('Power_ClearSky_Pane_I(W)')\n",
        "feature_cols.append('Power_ClearSky_Pane_II(W)')\n",
        "feature_cols.append('Total_Power_ClearSky_Output(W)')\n",
        "feature_cols.append('Month_Sin')\n",
        "feature_cols.append('DayOfYear_Sin')\n",
        "feature_cols.append('HourOfDay_Sin')\n",
        "feature_cols += level2_features\n",
        "\n",
        "print(f\"\\nTarget: {target_col}\")\n",
        "print(f\"Number of features: {len(feature_cols)}\")\n",
        "print(f\"Features: {feature_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop NaNs\n",
        "model_df = df_merge_hourly.dropna(subset=feature_cols + [target_col])\n",
        "X = model_df[feature_cols].values\n",
        "y = model_df[target_col].values.reshape(-1, 1)\n",
        "\n",
        "print(f\"Dataset shape: X={X.shape}, y={y.shape}\")\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Test set: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
        "\n",
        "# Normalize (Neural Networks work better with scaled data)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "y_test_scaled = scaler_y.transform(y_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
        "y_train_tensor = torch.FloatTensor(y_train_scaled).to(device)\n",
        "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
        "y_test_tensor = torch.FloatTensor(y_test_scaled).to(device)\n",
        "\n",
        "print(\"\\nData prepared and converted to PyTorch tensors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SolarPredictionNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SolarPredictionNN, self).__init__()\n",
        "        \n",
        "        # Define layers\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        \n",
        "        # Activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "input_dim = X_train.shape[1]\n",
        "model = SolarPredictionNN(input_dim).to(device)\n",
        "\n",
        "print(f\"Model initialized with input dimension: {input_dim}\")\n",
        "print(f\"\\nModel architecture:\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 200\n",
        "batch_size = 64\n",
        "\n",
        "print(f\"Training configuration:\")\n",
        "print(f\"  Loss function: MSE\")\n",
        "print(f\"  Optimizer: Adam (lr=0.001)\")\n",
        "print(f\"  Epochs: {num_epochs}\")\n",
        "print(f\"  Batch size: {batch_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Storage for loss history\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "print(\"Starting training...\\n\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    \n",
        "    # Mini-batch training\n",
        "    permutation = torch.randperm(X_train_tensor.size()[0])\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i in range(0, X_train_tensor.size()[0], batch_size):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = X_train_tensor[indices], y_train_tensor[indices]\n",
        "        \n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    # Calculate average training loss\n",
        "    avg_train_loss = epoch_loss / (X_train_tensor.size()[0] / batch_size)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    \n",
        "    # Evaluate on test set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor)\n",
        "        test_loss = criterion(test_outputs, y_test_tensor).item()\n",
        "        test_losses.append(test_loss)\n",
        "    \n",
        "    # Print progress\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.6f}, Test Loss: {test_loss:.6f}\")\n",
        "\n",
        "print(\"\\n\u2713 Training Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Train Loss', linewidth=2)\n",
        "plt.plot(test_losses, label='Test Loss', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss (MSE)', fontsize=12)\n",
        "plt.title('Training and Test Loss over Epochs', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions on test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = model(X_test_tensor).cpu().numpy()\n",
        "\n",
        "# Inverse transform to get actual values\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "y_test_actual = scaler_y.inverse_transform(y_test_scaled)\n",
        "\n",
        "# Apply physics constraints (no negative power output)\n",
        "y_pred = np.clip(y_pred, 0, None)\n",
        "y_test_actual = np.clip(y_test_actual, 0, None)\n",
        "\n",
        "print(\"Predictions generated and inverse-transformed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "mae = mean_absolute_error(y_test_actual, y_pred)\n",
        "mse = mean_squared_error(y_test_actual, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_actual, y_pred)\n",
        "\n",
        "# Normalized metrics\n",
        "capacity = y_test_actual.max()\n",
        "n_mae = (mae / capacity) * 100\n",
        "n_rmse = (rmse / capacity) * 100\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"Model Performance Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"MAE:    {mae:.2f} W\")\n",
        "print(f\"RMSE:   {rmse:.2f} W\")\n",
        "print(f\"R\u00b2:     {r2:.4f}\")\n",
        "print(f\"N-MAE:  {n_mae:.2f}%\")\n",
        "print(f\"N-RMSE: {n_rmse:.2f}%\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot predicted vs actual\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Scatter plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test_actual, y_pred, alpha=0.5, s=10)\n",
        "plt.plot([y_test_actual.min(), y_test_actual.max()], \n",
        "         [y_test_actual.min(), y_test_actual.max()], \n",
        "         'r--', linewidth=2, label='Perfect Prediction')\n",
        "plt.xlabel('Actual PV Output (W)', fontsize=12)\n",
        "plt.ylabel('Predicted PV Output (W)', fontsize=12)\n",
        "plt.title('Predicted vs Actual Solar Output', fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Residual plot\n",
        "plt.subplot(1, 2, 2)\n",
        "residuals = y_test_actual - y_pred\n",
        "plt.scatter(y_pred, residuals, alpha=0.5, s=10)\n",
        "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
        "plt.xlabel('Predicted PV Output (W)', fontsize=12)\n",
        "plt.ylabel('Residuals (W)', fontsize=12)\n",
        "plt.title('Residual Plot', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot a sample of predictions vs actual over time\n",
        "n_samples = min(200, len(y_test_actual))\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(range(n_samples), y_test_actual[:n_samples], \n",
        "         label='Actual', linewidth=2, alpha=0.7)\n",
        "plt.plot(range(n_samples), y_pred[:n_samples], \n",
        "         label='Predicted', linewidth=2, alpha=0.7)\n",
        "plt.xlabel('Sample Index', fontsize=12)\n",
        "plt.ylabel('PV Output (W)', fontsize=12)\n",
        "plt.title('Actual vs Predicted Solar Output (First 200 samples)', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model_path = f\"{MODEL_DIR}/pytorch_ann_model.pth\"\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scaler_X': scaler_X,\n",
        "    'scaler_y': scaler_y,\n",
        "    'feature_cols': feature_cols,\n",
        "    'target_col': target_col,\n",
        "    'train_losses': train_losses,\n",
        "    'test_losses': test_losses,\n",
        "    'metrics': {\n",
        "        'mae': mae,\n",
        "        'rmse': rmse,\n",
        "        'r2': r2,\n",
        "        'n_mae': n_mae,\n",
        "        'n_rmse': n_rmse\n",
        "    }\n",
        "}, model_path)\n",
        "\n",
        "print(f\"Model saved to: {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates a simple PyTorch Artificial Neural Network (ANN) for predicting solar output (PV in Watts).\n",
        "\n",
        "### Model Architecture:\n",
        "- Input Layer: Variable size based on features\n",
        "- Hidden Layer 1: 128 neurons with ReLU activation\n",
        "- Hidden Layer 2: 64 neurons with ReLU activation\n",
        "- Hidden Layer 3: 32 neurons with ReLU activation\n",
        "- Output Layer: 1 neuron (regression output)\n",
        "- Dropout: 0.2 for regularization\n",
        "\n",
        "### Training Configuration:\n",
        "- Optimizer: Adam with learning rate 0.001\n",
        "- Loss Function: Mean Squared Error (MSE)\n",
        "- Batch Size: 64\n",
        "- Epochs: 200\n",
        "\n",
        "### Key Features:\n",
        "- Uses same features as the KAN model for fair comparison\n",
        "- Includes weather features (temperature, humidity, wind, etc.)\n",
        "- Incorporates temporal features (time of day, day of year, month)\n",
        "- Uses clear sky power output as an important predictor\n",
        "\n",
        "The model can be used for real-time solar output prediction and energy forecasting."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}